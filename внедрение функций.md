Коротко: сделаем «тонкий» слой для function calling, который **перед основным ответом** модели один раз прогоняет последнее сообщение через инструмент `save_profile_fields`. Если модель видит новые поля профайла — вернёт вызов функции с JSON-аргументами; мы сохраним их в БД через твою `storage.set_profile_fields(...)`. Дальше всё работает, как и раньше: основной ответ формирует твой `get_vibe_checker_response(...)`. Ничего в архитектуре не ломаем.

Ниже — готовые вставки кода (drop-in). Я использую официальный гайд по Function Calling/Tools и Structured Outputs, чтобы схема была совместима с Responses API. ([OpenAI][1])

---

# 1) `openai_module.py` — добавляем инструмент и хелпер

Добавь рядом с остальным кодом (импорты: `import json` пригодится):

```python
# --- вставить в openai_module.py ---
import json

PROFILE_SAVE_TOOL = [
    {
        "type": "function",
        "function": {
            "name": "save_profile_fields",
            "description": (
                "Сохранить (частично обновить) профиль пользователя. "
                "Передавай ТОЛЬКО те поля, которые пользователь явно назвал или подтвердил. "
                "Поля: sex ('m'/'f'), age (int), height_cm (int), weight_kg (float/int), "
                "activity ('low'|'medium'|'high'), goal ('lose'|'maintain'|'gain'), "
                "allergies (string), diet (string)."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "sex":       {"type": "string", "enum": ["m", "f"]},
                    "age":       {"type": "integer"},
                    "height_cm": {"type": "integer"},
                    "weight_kg": {"type": "number"},
                    "activity":  {"type": "string", "enum": ["low", "medium", "high"]},
                    "goal":      {"type": "string", "enum": ["lose", "maintain", "gain"]},
                    "allergies": {"type": "string"},
                    "diet":      {"type": "string"}
                },
                "additionalProperties": False
                # Без strict/required — поля можно передавать частично (это проще для нашей задачи).
            },
        },
    }
]


async def maybe_update_profile_from_text(text: str, user_id: int) -> dict:
    """
    Одноразовый вызов модели с tools: если в тексте есть НОВЫЕ данные профиля —
    модель вызовет save_profile_fields с нужными аргументами. Мы их сохраним в БД.
    Возвращает dict обновлённых полей (или пустой dict).
    """
    if not text or user_id is None:
        return {}

    # Cжатая инструкция — модель только извлекает поля и вызывает функцию при необходимости
    instructions = (
        "Ты — парсер профиля. Если пользователь назвал новые данные профиля "
        "(sex, age, height_cm, weight_kg, activity, goal, allergies, diet), "
        "ВЫЗОВИ функцию save_profile_fields, заполняя ТОЛЬКО явно подтверждённые поля. "
        "Если новых данных нет — не вызывай функцию."
    )

    resp = await client.responses.create(
        model=OPENAI_MODEL,
        input=[
            {"role": "system", "content": instructions},
            {"role": "user", "content": text},
        ],
        tools=PROFILE_SAVE_TOOL,
        # tool_choice="auto"  # по умолчанию auto; можно явно указать
    )

    # Универсальный парсинг tool-call для Responses API
    updated = {}
    for item in getattr(resp, "output", []) or []:
        t = getattr(item, "type", None)
        if t in ("function_call", "tool_call"):
            name = getattr(item, "name", "")
            if name == "save_profile_fields":
                args_raw = getattr(item, "arguments", "") or getattr(item, "input", "")
                try:
                    args = json.loads(args_raw) if isinstance(args_raw, str) else (args_raw or {})
                except Exception:
                    args = {}
                if isinstance(args, dict) and args:
                    # Сохраняем в БД только разрешённые поля — твой метод это уже делает
                    await storage.set_profile_fields(user_id, **args)
                    updated = args
                break

    return updated
# --- конец вставки ---
```

Почему так:

* **tools / function calling** — это штатный способ дать модели право «вызвать вашу функцию» с валидными аргументами по JSON-схеме. Модель сама решает, звать ли функцию, и присылает `arguments` — вы просто выполняете свою логику. ([OpenAI][1])
* Мы не включали `strict: true`, чтобы оставить поля **опциональными** (частичное обновление). Если захочешь «строгость» по схеме, можно перейти на Structured Outputs c `strict` и юнионами `["string","null"]` для опциональности — это описано в гайде. ([OpenAI][2])

---

# 2) `main.py` — одно строчное подключение перед основным ответом

Найди место, где ты обрабатываешь обычное текстовое сообщение пользователя (там, где берёшь `message.text`, формируешь историю и звонишь `get_vibe_checker_response`). **Перед** вызовом твоей основной генерации ответа вставь:

```python
from openai_module import maybe_update_profile_from_text  # вверху файла

# ... внутри хэндлера сообщения, сразу после получения текста:
_ = await maybe_update_profile_from_text(message.text, user_id)
```

В итоге последовательность такая:

1. Сохранили входящее сообщение в историю (как и раньше).
2. **Быстрый «парсер» профиля** через function calling: при необходимости обновили БД.
3. Получили основной ответ через твой `get_vibe_checker_response(...)` и отправили пользователю.

Никаких изменений в базовой логике/Промпте/Клавиатурах не требуется.

> Если хочешь, чтобы ассистент **подтверждал обновления** фразой «Профиль обновлён: вес 82 кг, цель — снижение» — самый простой путь: после строки выше, если `dict` не пустой, добавь короткий `await message.answer("✅ Профиль обновлён …")`. Или можно передавать список обновлений обратно в промпт (в system/dev-роле) — модель сама аккуратно упомянет это в основном ответе.

---

# 3) Опционально — тот же механизм и для голосовых

Там, где ты уже получаешь транскрипт (`transcribe_voice`), добавь:

```python
if transcript:
    _ = await maybe_update_profile_from_text(transcript, user_id)
```

Это даст авто-обновление профиля и из войсов.

---

# 4) Что ещё можно докрутить (по желанию)

* **Строгая схема (Structured Outputs + strict)**: если захочешь, можно включить `strict: true` у функции и прописать `required` + юнионы `"type": ["string","null"]` для «опциональности». Тогда модель **гарантированно** вернёт JSON, соответствующий схеме. См. раздел про Structured Outputs. ([OpenAI][2])
* **Повторный прогон**: если модель сначала зовёт функцию, а потом хочет ответить человеку с учётом результата, можно сделать «второй проход»: добавить в `input` блок с результатом инструмента и снова вызвать `client.responses.create(...)`. Это типовой паттерн из гайдлайнов по tool-calling. ([OpenAI][1])

---

## Мини-проверка (ручной тест)

1. Пользователь пишет:
   «Мне 31, рост 178, вес 82. Цель — снизить. Активность — средняя».
   → Модель вызовет `save_profile_fields` с

   ```json
   {"age":31,"height_cm":178,"weight_kg":82,"goal":"lose","activity":"medium"}
   ```

   → БД обновлена. → Далее обычный ответ бота.

2. Пользователь:
   «Аллергия на орехи, диета — без молочного».
   → Вызов с `{"allergies":"орехи","diet":"без молочного"}`.

---

## Ссылки на доки, которые я использовал

* Function calling / Tools (как описывать функции и ловить вызовы). ([OpenAI][1])
* Structured Outputs (если захочешь строгую схему и «железобетонный» JSON). ([OpenAI][2])

---

Хочешь — могу сразу прислать вариант с `strict: true` и корректной схемой под **частичные** обновления (через `["string","null"]` и т.д.) или сделать подтверждение обновления в одном сообщении с основным ответом (двухпроходный вызов).

[1]: https://platform.openai.com/docs/guides/function-calling?utm_source=chatgpt.com "Function calling - OpenAI API"
[2]: https://platform.openai.com/docs/guides/structured-outputs?utm_source=chatgpt.com "OpenAI Structured Outputs Guide"
